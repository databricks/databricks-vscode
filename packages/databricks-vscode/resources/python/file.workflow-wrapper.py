#This file is autogenerated by the Databricks Extension for VS Code

import runpy
import sys
import os

databricks_arg_idx = []
for i, arg in enumerate(sys.argv):
    if i == 0:
        continue
    if sys.argv[i-1] == "--databricks-source-file":
        python_file = arg
    elif sys.argv[i-1] == "--databricks-project-root":
        project_root = arg
    else:
        continue
    databricks_arg_idx.extend([i, i-1])

if python_file is None:
    raise Exception("--databricks-source-file argument not specified")

if project_root is None:
    raise Exception("--databricks-project-root argument not specified")

#remove databricks args from argv
sys.argv = [value for i,value in enumerate(sys.argv) if i not in databricks_arg_idx]

# change working directory
os.chdir(os.path.dirname(python_file))

# update python path
sys.path.insert(0, project_root)

# provide spark globals
user_ns = {
    "display": display,
    "displayHTML": displayHTML,
    "dbutils": dbutils,
    "table": table,
    "sql": sql,
    "udf": udf,
    "getArgument": getArgument,
    "sc": sc,
    "spark": spark,
    "sqlContext": sqlContext,
}

# Set log level to "ERROR". See https://kb.databricks.com/notebooks/cmd-c-on-object-id-p0.html
import logging; logger = spark._jvm.org.apache.log4j;
logging.getLogger("py4j.java_gateway").setLevel(logging.ERROR)

runpy.run_path(python_file, run_name="__main__", init_globals=user_ns)
None
